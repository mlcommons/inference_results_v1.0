{
    "A100-PCIex1": {
        "audio_batch_size": 1024,
        "audio_buffer_num_lines": 4096,
        "audio_fp16_input": true,
        "dali_batches_issue_ahead": 0,
        "dali_pipeline_depth": 2,
        "gpu_batch_size": 2048,
        "gpu_copy_streams": 1,
        "nobatch_sorting": true,
        "num_warmups": 20480,
        "pipelined_execution": true,
        "server_target_qps": 11100
    },
    "A100-PCIex2": {
        "audio_batch_size": 1024,
        "audio_buffer_num_lines": 4096,
        "audio_fp16_input": true,
        "dali_batches_issue_ahead": 0,
        "dali_pipeline_depth": 2,
        "gpu_batch_size": 2048,
        "gpu_copy_streams": 1,
        "nobatch_sorting": true,
        "num_warmups": 20480,
        "pipelined_execution": true,
        "server_target_qps": 22000
    },
    "A100-PCIex8": {
        "config_ver": {
            "maxq": {}
        },
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 8.0
            }
        }
    },
    "A100-SXM-80GBx1": {
        "extends": [
            "A100-SXM4-40GBx1"
        ]
    },
    "A100-SXM-80GBx4": {
        "config_ver": {
            "maxq": {}
        },
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 4
            }
        }
    },
    "A100-SXM-80GBx8": {
        "config_ver": {
            "liquid" : {
                "server_target_qps": 105000,
                "gpu_batch_size": 2048,
                "gpu_copy_streams": 2,
                "gpu_inference_streams":1,
                "run_infer_on_copy_streams": true,
                "start_from_device": true
            }
        },
        "extends": [
            "A100-SXM4-40GBx8"
        ],
        "server_target_qps": 105000,
        "gpu_batch_size": 2048,
        "gpu_copy_streams": 2,
        "gpu_inference_streams":1,
        "run_infer_on_copy_streams": false,
        "start_from_device": true
    },
    "A100-SXM-80GB-MIG_1x1g.10gb": {
        "config_ver": {
            "hetero": {}
        },
        "scales": {
            "A100-SXM-80GBx1": {
                "server_target_qps": 0.12
            }
        },
        "audio_batch_size": 64,
        "audio_buffer_num_lines": 512,
        "dali_batches_issue_ahead": 2,
        "dali_pipeline_depth": 2,
        "gpu_copy_streams": 1,
        "num_warmups": 64,
        "start_from_device": false,
        "gpu_batch_size": 1024,
        "server_target_qps": 1300,
        "max_seq_length": 64
    },
    "A100-SXM4-40GBx1": {
        "audio_batch_size": 1024,
        "audio_buffer_num_lines": 4096,
        "audio_fp16_input": true,
        "dali_batches_issue_ahead": 0,
        "dali_pipeline_depth": 2,
        "gpu_batch_size": 1792,
        "gpu_copy_streams": 1,
        "nobatch_sorting": true,
        "num_warmups": 20480,
        "pipelined_execution": true,
        "server_target_qps": 12750,
        "start_from_device": true
    },
    "A100-SXM4-40GBx8": {
        "audio_batch_size": 1024,
        "audio_buffer_num_lines": 4096,
        "audio_fp16_input": true,
        "dali_batches_issue_ahead": 0,
        "dali_pipeline_depth": 1,
        "gpu_batch_size": 2048,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 1,
        "nobatch_sorting": true,
        "num_warmups": 20480,
        "pipelined_execution": true,
        "server_num_issue_query_threads": 0,
        "server_target_qps": 101600,
        "run_infer_on_copy_streams": false,
        "start_from_device": true
    },
    "A10x1": {
        "audio_batch_size": 128,
        "audio_buffer_num_lines": 4096,
        "dali_batches_issue_ahead": 0,
        "dali_pipeline_depth": 1,
        "gpu_batch_size": 512,
        "gpu_copy_streams": 2,
        "gpu_inference_streams": 2,
        "nobatch_sorting": true,
        "num_warmups": 2048,
        "server_target_qps": 3300
    },
    "A10x8": {
        "scales": {
            "A10x1": {
                "server_target_qps": 6.85
            }
        },
        "gpu_copy_streams": 2,
        "gpu_inference_streams": 2
    },
    "A30x1": {
        "gpu_batch_size": 1792,
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 0.58
            }
        },
        "server_target_qps": 5200
    },
    "A30x8": {
        "config_ver": {
            "maxq": {}
        },
        "gpu_batch_size": 1792,
        "scales": {
            "A100-PCIex8": {
                "server_target_qps": 0.58
            }
        },
        "server_target_qps": 40000
    },
    "A30-MIG_1x1g.3gb": {
        "config_ver": {
            "hetero": {}
        },
        "scales": {
            "A30x1": {
                "server_target_qps": 0.25
            }
        }
    },
    "T4x1": {
        "audio_batch_size": 64,
        "audio_buffer_num_lines": 512,
        "dali_batches_issue_ahead": 0,
        "dali_pipeline_depth": 1,
        "disable_encoder_plugin": true,
        "gpu_batch_size": 256,
        "gpu_copy_streams": 4,
        "max_seq_length": 102,
        "nobatch_sorting": true,
        "num_warmups": 2048,
        "server_target_qps": 1050
    },
    "T4x20": {
        "audio_batch_size": 64,
        "audio_buffer_num_lines": 512,
        "dali_batches_issue_ahead": 0,
        "dali_pipeline_depth": 1,
        "disable_encoder_plugin": true,
        "gpu_batch_size": 256,
        "gpu_copy_streams": 4,
        "max_seq_length": 102,
        "nobatch_sorting": true,
        "num_warmups": 20480,
        "server_target_qps": 17000
    },
    "T4x8": {
        "audio_batch_size": 64,
        "audio_buffer_num_lines": 640,
        "dali_batches_issue_ahead": 0,
        "dali_pipeline_depth": 1,
        "disable_encoder_plugin": true,
        "gpu_batch_size": 320,
        "gpu_copy_streams": 4,
        "max_seq_length": 102,
        "nobatch_sorting": true,
        "num_warmups": 20480,
        "server_target_qps": 8100
    },
    "TitanRTXx1": {
        "disable_encoder_plugin": true,
        "gpu_batch_size": 2048,
        "gpu_copy_streams": 1,
        "server_target_qps": 1600
    },
    "TitanRTXx4": {
        "audio_batch_size": 128,
        "disable_encoder_plugin": true,
        "gpu_batch_size": 2048,
        "gpu_copy_streams": 1,
        "server_target_qps": 11000
    },
    "benchmark": "rnnt",
    "default": {
        "gpu_inference_streams": 1,
        "input_dtype": "fp16",
        "input_format": "linear",
        "map_path": "data_maps/rnnt_dev_clean_512/val_map.txt",
        "precision": "fp16",
        "tensor_path": "${PREPROCESSED_DATA_DIR}/rnnt_dev_clean_512/fp16",
        "use_graphs": true
    },
    "scenario": "Server"
}
